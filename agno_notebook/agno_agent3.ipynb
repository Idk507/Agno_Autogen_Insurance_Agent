{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0688566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import pypdf\n",
    "from docx import Document as DocxDocument\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from agno.agent import Agent\n",
    "from agno.tools.reasoning import ReasoningTools\n",
    "from agno.memory.v2.memory import Memory\n",
    "from agno.memory.v2.db.sqlite import SqliteMemoryDb\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df097632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI Configuration\n",
    "AZURE_CONFIG = {\n",
    "    \"api_key\": \"\", \n",
    "    \"endpoint\": \"\",\n",
    "    \"api_version\": \"2024-12-01-preview\",\n",
    "    \"embedding_deployment\": \"text-embedding-ada-002\",\n",
    "    \"gpt_deployment\": \"gpt-4o\"\n",
    "}\n",
    "\n",
    "# Initialize Azure OpenAI clients\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_key=AZURE_CONFIG[\"api_key\"],\n",
    "    azure_endpoint=AZURE_CONFIG[\"endpoint\"],\n",
    "    api_version=AZURE_CONFIG[\"api_version\"],\n",
    "    deployment_name=AZURE_CONFIG[\"gpt_deployment\"],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    openai_api_key=AZURE_CONFIG[\"api_key\"],\n",
    "    azure_endpoint=AZURE_CONFIG[\"endpoint\"],\n",
    "    api_version=AZURE_CONFIG[\"api_version\"],\n",
    "    deployment=AZURE_CONFIG[\"embedding_deployment\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e6823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Custom tool for document summarization\n",
    "class DocumentSummaryTool:\n",
    "    name = \"document_summary\"\n",
    "    description = \"Summarizes a document chunk for concise understanding.\"\n",
    "    \n",
    "    def run(self, document_text: str) -> str:\n",
    "        \"\"\"Summarize a document chunk using the LLM.\"\"\"\n",
    "        try:\n",
    "            prompt = f\"Summarize the following document text in 2-3 sentences:\\n{document_text}\"\n",
    "            summary = llm.invoke(prompt).content\n",
    "            logger.info(\"Generated document summary\")\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error summarizing document: {e}\")\n",
    "            return \"Unable to summarize document.\"\n",
    "\n",
    "# InsuranceRAGSystem: Manages document ingestion, embedding, and retrieval\n",
    "class InsuranceRAGSystem:\n",
    "    def __init__(self, data_dir=\"data\", db_dir=\"chroma_db\"):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.db_dir = Path(db_dir)\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        self.vectorstore = None\n",
    "        logger.info(\"Initializing InsuranceRAGSystem\")\n",
    "        # Ensure data directory exists before embedding\n",
    "        self.initialize_data_dir()\n",
    "        self.embed_documents()\n",
    "\n",
    "    def initialize_data_dir(self):\n",
    "        \"\"\"Create data directory and sample document if empty.\"\"\"\n",
    "        if not self.data_dir.exists():\n",
    "            self.data_dir.mkdir(parents=True, exist_ok=True)\n",
    "            logger.info(f\"Created data directory at {self.data_dir}\")\n",
    "            self.create_sample_document()\n",
    "        elif not any(self.data_dir.iterdir()):\n",
    "            self.create_sample_document()\n",
    "        logger.info(f\"Data directory initialized at {self.data_dir}\")\n",
    "\n",
    "    def create_sample_document(self):\n",
    "        \"\"\"Create a sample insurance document if none exist.\"\"\"\n",
    "        sample_content = \"\"\"\n",
    "        # Insurance Basics\n",
    "        ## Auto Insurance Types\n",
    "        - **Liability Coverage**: Covers damages to others if you're at fault in an accident.\n",
    "        - **Collision Coverage**: Covers damage to your car from a collision.\n",
    "        - **Comprehensive Coverage**: Covers non-collision damage (e.g., theft, natural disasters).\n",
    "        - **Personal Injury Protection (PIP)**: Covers medical expenses for you and your passengers.\n",
    "        ## Home Insurance Claims\n",
    "        - **Step 1**: Contact your insurance provider immediately.\n",
    "        - **Step 2**: Document the damage with photos and videos.\n",
    "        - **Step 3**: Submit a claim form with detailed descriptions.\n",
    "        \"\"\"\n",
    "        # For testing, create multiple files if they don't exist to match log output\n",
    "        files_to_create = {\n",
    "            \"sample_insurance_info.txt\": sample_content,\n",
    "            \"auto_insurance.txt\": \"Details about auto insurance policies...\",\n",
    "            \"home_insurance.txt\": \"Information on home insurance claims and coverage...\",\n",
    "            \"life_insurance.txt\": \"Understanding life insurance options...\"\n",
    "        }\n",
    "        for filename, content in files_to_create.items():\n",
    "            filepath = self.data_dir / filename\n",
    "            if not filepath.exists():\n",
    "                 with open(filepath, \"w\") as f:\n",
    "                    f.write(content)\n",
    "                 logger.info(f\"Created sample document: {filename}\")\n",
    "\n",
    "\n",
    "    def load_documents(self):\n",
    "        \"\"\"Load and process documents from data directory.\"\"\"\n",
    "        documents = []\n",
    "        for file_path in self.data_dir.iterdir():\n",
    "            if file_path.suffix.lower() in [\".pdf\", \".txt\", \".docx\"]:\n",
    "                content = self.read_file(file_path)\n",
    "                if content:\n",
    "                    doc = Document(page_content=content, metadata={\"source\": str(file_path)})\n",
    "                    documents.append(doc)\n",
    "                    logger.info(f\"Loaded document: {file_path}\")\n",
    "        return documents\n",
    "\n",
    "    def read_file(self, file_path):\n",
    "        \"\"\"Read content from PDF, text, or Word files.\"\"\"\n",
    "        try:\n",
    "            if file_path.suffix.lower() == \".pdf\":\n",
    "                with open(file_path, \"rb\") as f:\n",
    "                    pdf = pypdf.PdfReader(f)\n",
    "                    text = \"\".join(page.extract_text() for page in pdf.pages if page.extract_text())\n",
    "                    return text\n",
    "            elif file_path.suffix.lower() == \".txt\":\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    return f.read()\n",
    "            elif file_path.suffix.lower() == \".docx\":\n",
    "                doc = DocxDocument(file_path)\n",
    "                return \"\\n\".join(paragraph.text for paragraph in doc.paragraphs if paragraph.text)\n",
    "            return \"\"\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading {file_path}: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def embed_documents(self):\n",
    "        \"\"\"Embed all documents and store in ChromaDB.\"\"\"\n",
    "        try:\n",
    "            # self.initialize_data_dir() # Already called in __init__\n",
    "            documents = self.load_documents()\n",
    "            if not documents:\n",
    "                logger.warning(\"No documents found in data directory. Attempting to create sample document.\")\n",
    "                self.create_sample_document() # Ensure sample is created if dir was empty\n",
    "                documents = self.load_documents()\n",
    "                if not documents:\n",
    "                    logger.error(\"Still no documents found after attempting to create sample. Aborting embedding.\")\n",
    "                    return\n",
    "\n",
    "            chunks = self.text_splitter.split_documents(documents)\n",
    "            if not chunks:\n",
    "                logger.warning(\"No chunks to embed after splitting documents.\")\n",
    "                return\n",
    "\n",
    "            # Ensure the persist directory exists\n",
    "            self.db_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            self.vectorstore = Chroma.from_documents(\n",
    "                documents=chunks,\n",
    "                embedding=embeddings,\n",
    "                persist_directory=str(self.db_dir)\n",
    "            )\n",
    "            self.vectorstore.persist()\n",
    "            logger.info(f\"Embedded {len(chunks)} document chunks into {self.db_dir}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error embedding documents: {e}\")\n",
    "            raise\n",
    "\n",
    "    def search(self, query):\n",
    "        \"\"\"Search for relevant documents based on query.\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            # Attempt to load an existing vectorstore if not initialized\n",
    "            if self.db_dir.exists() and any(self.db_dir.iterdir()):\n",
    "                try:\n",
    "                    self.vectorstore = Chroma(persist_directory=str(self.db_dir), embedding_function=embeddings)\n",
    "                    logger.info(f\"Loaded existing vectorstore from {self.db_dir}\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error loading existing vectorstore: {e}. Please reload/reset.\")\n",
    "                    return []\n",
    "            else:\n",
    "                logger.warning(\"Vectorstore not initialized and no existing store found. Please load/embed documents.\")\n",
    "                return []\n",
    "        try:\n",
    "            docs = self.vectorstore.similarity_search(query, k=3)\n",
    "            logger.info(f\"Retrieved {len(docs)} documents for query: {query}\")\n",
    "            return docs\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error searching documents: {e}\")\n",
    "            return []\n",
    "\n",
    "    def stats(self):\n",
    "        \"\"\"Return statistics about stored documents.\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            if self.db_dir.exists() and any(self.db_dir.iterdir()): # Try to load if not loaded\n",
    "                try:\n",
    "                    self.vectorstore = Chroma(persist_directory=str(self.db_dir), embedding_function=embeddings)\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Could not load vectorstore for stats: {e}\")\n",
    "                    return \"No documents loaded (failed to load existing).\"\n",
    "            else:\n",
    "                return \"No documents loaded.\"\n",
    "        try:\n",
    "            count = self.vectorstore._collection.count()\n",
    "            logger.info(f\"Vectorstore stats: {count} documents\")\n",
    "            return f\"Number of documents: {count}\"\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting vectorstore stats: {e}\")\n",
    "            return \"Error retrieving stats.\"\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the vectorstore.\"\"\"\n",
    "        try:\n",
    "            if self.db_dir.exists():\n",
    "                import shutil\n",
    "                shutil.rmtree(self.db_dir) # Simpler and more robust way to delete directory\n",
    "                logger.info(f\"Removed existing ChromaDB directory: {self.db_dir}\")\n",
    "            self.db_dir.mkdir(parents=True, exist_ok=True) # Recreate directory\n",
    "            self.vectorstore = None # Clear in-memory vectorstore\n",
    "            self.embed_documents() # Re-initialize and embed\n",
    "            logger.info(\"Vectorstore reset and re-embedded\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error resetting vectorstore: {e}\")\n",
    "\n",
    "# InsuranceMultiAgentSystem: Manages collaborative agents with enhanced Agno features\n",
    "class InsuranceMultiAgentSystem:\n",
    "    def __init__(self, rag_system, llm_client): # Renamed llm to llm_client to avoid clash\n",
    "        self.rag_system = rag_system\n",
    "        self.llm_client = llm_client # Use renamed llm\n",
    "        self.memory = ConversationBufferMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            return_messages=True\n",
    "        )\n",
    "        \n",
    "        # Ensure 'tmp' directory exists for SQLite DB\n",
    "        Path(\"tmp\").mkdir(exist_ok=True)\n",
    "        try:\n",
    "            self.sqlite_memory_db = SqliteMemoryDb(table_name=\"insurance_memories\", db_file=\"tmp/agent.db\")\n",
    "            self.sqlite_memory = Memory(db=self.sqlite_memory_db)\n",
    "            logger.info(\"Initialized SQLite memory at tmp/agent.db\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error initializing SQLite memory: {e}\")\n",
    "            raise\n",
    "        self.initialize_agents()\n",
    "\n",
    "    def initialize_agents(self):\n",
    "        \"\"\"Initialize the team of agents with Agno features.\"\"\"\n",
    "        knowledge_retriever_instructions = [\n",
    "            \"You are a KnowledgeRetriever. Use the provided context to answer the user's question.\",\n",
    "            \"Focus on retrieving accurate information from insurance documents.\",\n",
    "            \"Use reasoning to ensure relevance and accuracy.\",\n",
    "            \"Summarize document content if it is lengthy.\"\n",
    "        ]\n",
    "        claims_specialist_instructions = [\n",
    "            \"You are a ClaimsSpecialist. Provide detailed guidance on handling insurance claims.\",\n",
    "            \"Explain steps clearly, including any documentation or processes required.\",\n",
    "            \"Use reasoning to address edge cases and potential user concerns.\"\n",
    "        ]\n",
    "        policy_advisor_instructions = [\n",
    "            \"You are a PolicyAdvisor. Offer expert advice on insurance policy options.\",\n",
    "            \"Explain policy types, coverage details, and considerations for choosing them.\",\n",
    "            \"Use reasoning to tailor advice to the user's query.\"\n",
    "        ]\n",
    "        customer_service_instructions = [\n",
    "            \"You are a CustomerService agent. Greet the user warmly and coordinate responses.\",\n",
    "            \"Ensure the user's question is clearly understood before passing it to other agents.\",\n",
    "            \"Use memory to personalize responses based on past interactions.\"\n",
    "        ]\n",
    "        lead_agent_instructions = [\n",
    "            \"You are a LeadAgent coordinating a team of specialized insurance agents.\",\n",
    "            \"Collect responses from the KnowledgeRetriever, ClaimsSpecialist, PolicyAdvisor, and CustomerService agents.\",\n",
    "            \"Use reasoning to summarize and refine their inputs into a clear, concise, and accurate response.\",\n",
    "            \"Return the response in JSON format with fields: 'answer' (string), 'sources' (list of strings), and 'confidence' (float between 0 and 1).\"\n",
    "        ]\n",
    "\n",
    "        self.knowledge_retriever = Agent(\n",
    "            name=\"KnowledgeRetriever\",\n",
    "            model=self.llm_client,\n",
    "            instructions=knowledge_retriever_instructions,\n",
    "            tools=[ReasoningTools(add_instructions=True), DocumentSummaryTool()],\n",
    "            memory=self.sqlite_memory,\n",
    "            enable_agentic_memory=True,\n",
    "            description=\"Retrieves and summarizes information from insurance documents.\",\n",
    "            markdown=True\n",
    "        )\n",
    "        self.claims_specialist = Agent(\n",
    "            name=\"ClaimsSpecialist\",\n",
    "            model=self.llm_client,\n",
    "            instructions=claims_specialist_instructions,\n",
    "            tools=[ReasoningTools(add_instructions=True)],\n",
    "            memory=self.sqlite_memory,\n",
    "            enable_agentic_memory=True,\n",
    "            description=\"Specializes in insurance claim processes.\",\n",
    "            markdown=True\n",
    "        )\n",
    "        self.policy_advisor = Agent(\n",
    "            name=\"PolicyAdvisor\",\n",
    "            model=self.llm_client,\n",
    "            instructions=policy_advisor_instructions,\n",
    "            tools=[ReasoningTools(add_instructions=True)],\n",
    "            memory=self.sqlite_memory,\n",
    "            enable_agentic_memory=True,\n",
    "            description=\"Advises on insurance policy options.\",\n",
    "            markdown=True\n",
    "        )\n",
    "        self.customer_service = Agent(\n",
    "            name=\"CustomerService\",\n",
    "            model=self.llm_client,\n",
    "            instructions=customer_service_instructions,\n",
    "            tools=[ReasoningTools(add_instructions=True)],\n",
    "            memory=self.sqlite_memory,\n",
    "            enable_agentic_memory=True,\n",
    "            description=\"Coordinates responses and greets users.\",\n",
    "            markdown=True\n",
    "        )\n",
    "        self.lead_agent = Agent(\n",
    "            name=\"LeadAgent\",\n",
    "            model=self.llm_client,\n",
    "            team=[self.knowledge_retriever, self.claims_specialist, self.policy_advisor, self.customer_service],\n",
    "            instructions=lead_agent_instructions,\n",
    "            tools=[ReasoningTools(add_instructions=True)],\n",
    "            memory=self.sqlite_memory,\n",
    "            enable_agentic_memory=True,\n",
    "            description=\"Coordinates the insurance agent team and provides JSON responses.\",\n",
    "            markdown=True\n",
    "        )\n",
    "        logger.info(\"Agents initialized with ReasoningTools, DocumentSummaryTool, and SQLite memory\")\n",
    "\n",
    "    def answer_question(self, question):\n",
    "        \"\"\"Process a question through the agent team.\"\"\"\n",
    "        memory_context = \"\"\n",
    "        try:\n",
    "            if hasattr(self.sqlite_memory, 'db') and hasattr(self.sqlite_memory.db, 'get_messages'):\n",
    "                # Ensure sqlite_memory.db (SqliteMemoryDb instance) is used\n",
    "                past_memories = self.sqlite_memory.db.get_messages()[-3:] \n",
    "                # Use .get() for safer dictionary access\n",
    "                memory_context = \"\\n\".join([f\"Past Q: {m.get('message', '')}\\nPast A: {m.get('response', '')}\" for m in past_memories])\n",
    "                if memory_context:\n",
    "                    logger.info(\"Retrieved recent past memories for personalization\")\n",
    "            else:\n",
    "                logger.warning(\"SQLite memory object or its 'db' attribute does not have 'get_messages' method.\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error retrieving memory messages: {e}\")\n",
    "        \n",
    "        docs = self.rag_system.search(question)\n",
    "        context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "        sources = [doc.metadata.get('source', 'Unknown source') for doc in docs]\n",
    "        \n",
    "        cs_prompt = (\n",
    "            f\"Greetings! I'm here to help with your insurance question: {question}\\n\"\n",
    "            f\"Past interactions:\\n{memory_context}\\n\"\n",
    "            f\"Instructions: {self.customer_service.instructions[0]}\"\n",
    "        )\n",
    "        cs_response = self.llm_client.invoke(cs_prompt).content\n",
    "        \n",
    "        doc_summary_tool = DocumentSummaryTool() # Instantiate the tool\n",
    "        doc_summary = doc_summary_tool.run(context) if context else \"No relevant documents found.\"\n",
    "        kr_prompt = (\n",
    "            f\"Question: {question}\\n\"\n",
    "            f\"Document Summary: {doc_summary}\\n\"\n",
    "            f\"Raw Context: {context}\\n\"\n",
    "            f\"Instructions: {self.knowledge_retriever.instructions[0]}\"\n",
    "        )\n",
    "        kr_response = self.llm_client.invoke(kr_prompt).content\n",
    "        \n",
    "        cspecial_prompt = f\"Question: {question}\\nInstructions: {self.claims_specialist.instructions[0]}\"\n",
    "        cspecial_response = self.llm_client.invoke(cspecial_prompt).content\n",
    "        \n",
    "        pa_prompt = f\"Question: {question}\\nInstructions: {self.policy_advisor.instructions[0]}\"\n",
    "        pa_response = self.llm_client.invoke(pa_prompt).content\n",
    "        \n",
    "        inputs = (\n",
    "            f\"CustomerService: {cs_response}\\n\"\n",
    "            f\"KnowledgeRetriever: {kr_response}\\n\"\n",
    "            f\"ClaimsSpecialist: {cspecial_response}\\n\"\n",
    "            f\"PolicyAdvisor: {pa_response}\"\n",
    "        )\n",
    "        # The LeadAgent itself should use its team and tools. Direct LLM call for lead_agent is not standard for Agno.\n",
    "        # However, to match the original structure closely for now:\n",
    "        lead_agent_prompt = (\n",
    "            f\"Question: {question}\\nInputs from team:\\n{inputs}\\n\"\n",
    "            # The lead_agent_instructions already specify JSON output. Adding it again to prompt might be redundant\n",
    "            # but keeping it for consistency with the original snippet's intent.\n",
    "            f\"Instructions: {self.lead_agent.instructions[0]}\\n\"\n",
    "             \"Return the response in JSON format with fields: 'answer' (string), 'sources' (list of strings), and 'confidence' (float).\"\n",
    "        )\n",
    "\n",
    "        json_response_str = self.llm_client.invoke(lead_agent_prompt).content\n",
    "        \n",
    "        response_dict = {}\n",
    "        try:\n",
    "            response_dict = json.loads(json_response_str)\n",
    "            if not isinstance(response_dict, dict) or 'answer' not in response_dict:\n",
    "                logger.warning(f\"Lead agent output not in expected JSON dict format. Output: {json_response_str}\")\n",
    "                response_dict = {'answer': json_response_str, 'sources': sources, 'confidence': 0.7} # Fallback\n",
    "            if 'sources' not in response_dict or not response_dict['sources']: # Ensure sources from RAG are included if agent doesn't provide\n",
    "                response_dict['sources'] = sources\n",
    "            if 'confidence' not in response_dict:\n",
    "                response_dict['confidence'] = 0.85 # Default confidence if not provided\n",
    "        except json.JSONDecodeError:\n",
    "            logger.warning(f\"Failed to parse JSON from lead agent: {json_response_str}\")\n",
    "            response_dict = {'answer': json_response_str, 'sources': sources, 'confidence': 0.6} # Fallback\n",
    "\n",
    "        self.memory.save_context({\"input\": question}, {\"output\": response_dict['answer']})\n",
    "        \n",
    "        try:\n",
    "            # Ensure sqlite_memory.db (SqliteMemoryDb instance) is used for add_message\n",
    "            if hasattr(self.sqlite_memory, 'db') and hasattr(self.sqlite_memory.db, 'add_message'):\n",
    "                 self.sqlite_memory.db.add_message({\"message\": question, \"response\": response_dict['answer']})\n",
    "            else:\n",
    "                logger.error(\"SQLite memory object or its 'db' attribute does not have 'add_message' method.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error adding message to SQLite memory: {e}\")\n",
    "            \n",
    "        logger.info(f\"Processed question: {question}\")\n",
    "        return response_dict, docs\n",
    "\n",
    "\n",
    "# Main program\n",
    "def main():\n",
    "    # Initialize systems\n",
    "    rag_system = InsuranceRAGSystem()\n",
    "    # Pass the global llm client to the multi_agent_system\n",
    "    multi_agent_system = InsuranceMultiAgentSystem(rag_system, llm)\n",
    "\n",
    "\n",
    "    sample_questions = [\n",
    "        \"What types of auto insurance should I consider?\",\n",
    "        \"How do I file a home insurance claim?\"\n",
    "    ]\n",
    "\n",
    "    print(\"Testing with sample questions:\")\n",
    "    for question in sample_questions:\n",
    "        print(f\"\\nQuestion: {question}\")\n",
    "        response, docs = multi_agent_system.answer_question(question)\n",
    "        print(f\"Answer: {response.get('answer', 'N/A')}\")\n",
    "        print(f\"Sources: {response.get('sources', [])}\")\n",
    "        print(f\"Confidence: {response.get('confidence', 0.0)}\")\n",
    "        print(\"Relevant Documents:\")\n",
    "        if docs:\n",
    "            for doc_item in docs: # Renamed doc to doc_item to avoid conflict if doc is used above\n",
    "                print(f\"- {doc_item.metadata.get('source', 'Unknown')}: {doc_item.page_content[:100]}...\")\n",
    "        else:\n",
    "            print(\"No relevant documents found.\")\n",
    "\n",
    "\n",
    "    print(\"\\nInteractive Mode - Type your question or use commands: stats, search [query], reload, reset, quit\")\n",
    "    while True:\n",
    "        user_input = input(\"\\nYour input: \").strip()\n",
    "        if user_input.lower() == \"quit\":\n",
    "            break\n",
    "        elif user_input.lower() == \"stats\":\n",
    "            print(rag_system.stats())\n",
    "        elif user_input.lower().startswith(\"search \"):\n",
    "            query = user_input[len(\"search \"):].strip()\n",
    "            retrieved_docs = rag_system.search(query) # Renamed to avoid conflict\n",
    "            print(\"Search Results:\")\n",
    "            if retrieved_docs:\n",
    "                for doc_item in retrieved_docs:\n",
    "                    print(f\"- {doc_item.metadata.get('source', 'Unknown')}: {doc_item.page_content[:100]}...\")\n",
    "            else:\n",
    "                print(\"No documents found for your search query.\")\n",
    "        elif user_input.lower() == \"reload\":\n",
    "            print(\"Reloading documents...\")\n",
    "            rag_system.embed_documents()\n",
    "            print(\"Documents reloaded.\")\n",
    "        elif user_input.lower() == \"reset\":\n",
    "            print(\"Resetting vectorstore...\")\n",
    "            rag_system.reset()\n",
    "            print(\"Vectorstore reset.\")\n",
    "        else:\n",
    "            response, retrieved_docs = multi_agent_system.answer_question(user_input) # Renamed to avoid conflict\n",
    "            print(f\"Answer: {response.get('answer', 'N/A')}\")\n",
    "            print(f\"Sources: {response.get('sources', [])}\")\n",
    "            print(f\"Confidence: {response.get('confidence', 0.0)}\")\n",
    "            print(\"Relevant Documents:\")\n",
    "            if retrieved_docs:\n",
    "                for doc_item in retrieved_docs:\n",
    "                    print(f\"- {doc_item.metadata.get('source', 'Unknown')}: {doc_item.page_content[:100]}...\")\n",
    "            else:\n",
    "                print(\"No relevant documents found.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
