{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b64dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import pypdf\n",
    "from docx import Document as DocxDocument\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from agno.agent import Agent\n",
    "from agno.tools.reasoning import ReasoningTools\n",
    "from agno.memory.v2.memory import Memory\n",
    "from agno.memory.v2.db.sqlite import SqliteMemoryDb\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9defc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI Configuration\n",
    "AZURE_CONFIG = {\n",
    "    \"api_key\": \"\",\n",
    "    \"endpoint\": \"\",\n",
    "    \"api_version\": \"2024-12-01-preview\",\n",
    "    \"embedding_deployment\": \"text-embedding-ada-002\",\n",
    "    \"gpt_deployment\": \"gpt-4o\"\n",
    "}\n",
    "\n",
    "# Initialize Azure OpenAI clients\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_key=AZURE_CONFIG[\"api_key\"],\n",
    "    azure_endpoint=AZURE_CONFIG[\"endpoint\"],\n",
    "    api_version=AZURE_CONFIG[\"api_version\"],\n",
    "    deployment_name=AZURE_CONFIG[\"gpt_deployment\"],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    openai_api_key=AZURE_CONFIG[\"api_key\"],\n",
    "    azure_endpoint=AZURE_CONFIG[\"endpoint\"],\n",
    "    api_version=AZURE_CONFIG[\"api_version\"],\n",
    "    deployment=AZURE_CONFIG[\"embedding_deployment\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d30d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Custom tool for document summarization\n",
    "class DocumentSummaryTool:\n",
    "    name = \"document_summary\"\n",
    "    description = \"Summarizes a document chunk for concise understanding.\"\n",
    "    \n",
    "    def run(self, document_text: str) -> str:\n",
    "        \"\"\"Summarize a document chunk using the LLM.\"\"\"\n",
    "        try:\n",
    "            prompt = f\"Summarize the following document text in 2-3 sentences:\\n{document_text}\"\n",
    "            summary = llm.invoke(prompt).content\n",
    "            logger.info(\"Generated document summary\")\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error summarizing document: {e}\")\n",
    "            return \"Unable to summarize document.\"\n",
    "\n",
    "# InsuranceRAGSystem: Manages document ingestion, embedding, and retrieval\n",
    "class InsuranceRAGSystem:\n",
    "    def __init__(self, data_dir=\"data\", db_dir=\"chroma_db\"):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.db_dir = Path(db_dir)\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        self.vectorstore = None\n",
    "        logger.info(\"Initializing InsuranceRAGSystem\")\n",
    "        self.embed_documents()\n",
    "\n",
    "    def initialize_data_dir(self):\n",
    "        \"\"\"Create data directory and sample document if empty.\"\"\"\n",
    "        if not self.data_dir.exists():\n",
    "            self.data_dir.mkdir()\n",
    "            self.create_sample_document()\n",
    "        elif not any(self.data_dir.iterdir()):\n",
    "            self.create_sample_document()\n",
    "        logger.info(f\"Data directory initialized at {self.data_dir}\")\n",
    "\n",
    "    def create_sample_document(self):\n",
    "        \"\"\"Create a sample insurance document if none exist.\"\"\"\n",
    "        sample_content = \"\"\"\n",
    "        # Insurance Basics\n",
    "        ## Auto Insurance Types\n",
    "        - **Liability Coverage**: Covers damages to others if you're at fault in an accident.\n",
    "        - **Collision Coverage**: Covers damage to your car from a collision.\n",
    "        - **Comprehensive Coverage**: Covers non-collision damage (e.g., theft, natural disasters).\n",
    "        - **Personal Injury Protection (PIP)**: Covers medical expenses for you and your passengers.\n",
    "        ## Home Insurance Claims\n",
    "        - **Step 1**: Contact your insurance provider immediately.\n",
    "        - **Step 2**: Document the damage with photos and videos.\n",
    "        - **Step 3**: Submit a claim form with detailed descriptions.\n",
    "        \"\"\"\n",
    "        with open(self.data_dir / \"sample_insurance_info.txt\", \"w\") as f:\n",
    "            f.write(sample_content)\n",
    "        logger.info(\"Created sample document\")\n",
    "\n",
    "    def load_documents(self):\n",
    "        \"\"\"Load and process documents from data directory.\"\"\"\n",
    "        documents = []\n",
    "        for file_path in self.data_dir.iterdir():\n",
    "            if file_path.suffix.lower() in [\".pdf\", \".txt\", \".docx\"]:\n",
    "                content = self.read_file(file_path)\n",
    "                if content:\n",
    "                    doc = Document(page_content=content, metadata={\"source\": str(file_path)})\n",
    "                    documents.append(doc)\n",
    "                    logger.info(f\"Loaded document: {file_path}\")\n",
    "        return documents\n",
    "\n",
    "    def read_file(self, file_path):\n",
    "        \"\"\"Read content from PDF, text, or Word files.\"\"\"\n",
    "        try:\n",
    "            if file_path.suffix.lower() == \".pdf\":\n",
    "                with open(file_path, \"rb\") as f:\n",
    "                    pdf = pypdf.PdfReader(f)\n",
    "                    text = \"\".join(page.extract_text() for page in pdf.pages if page.extract_text())\n",
    "                    return text\n",
    "            elif file_path.suffix.lower() == \".txt\":\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    return f.read()\n",
    "            elif file_path.suffix.lower() == \".docx\":\n",
    "                doc = DocxDocument(file_path)\n",
    "                return \"\\n\".join(paragraph.text for paragraph in doc.paragraphs if paragraph.text)\n",
    "            return \"\"\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading {file_path}: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def embed_documents(self):\n",
    "        \"\"\"Embed all documents and store in ChromaDB.\"\"\"\n",
    "        try:\n",
    "            self.initialize_data_dir()\n",
    "            documents = self.load_documents()\n",
    "            if not documents:\n",
    "                self.create_sample_document()\n",
    "                documents = self.load_documents()\n",
    "            \n",
    "            chunks = self.text_splitter.split_documents(documents)\n",
    "            self.vectorstore = Chroma.from_documents(\n",
    "                documents=chunks,\n",
    "                embedding=embeddings,\n",
    "                persist_directory=str(self.db_dir)\n",
    "            )\n",
    "            self.vectorstore.persist()\n",
    "            logger.info(f\"Embedded {len(chunks)} document chunks into {self.db_dir}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error embedding documents: {e}\")\n",
    "            raise\n",
    "\n",
    "    def search(self, query):\n",
    "        \"\"\"Search for relevant documents based on query.\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            logger.warning(\"Vectorstore not initialized\")\n",
    "            return []\n",
    "        try:\n",
    "            docs = self.vectorstore.similarity_search(query, k=3)\n",
    "            logger.info(f\"Retrieved {len(docs)} documents for query: {query}\")\n",
    "            return docs\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error searching documents: {e}\")\n",
    "            return []\n",
    "\n",
    "    def stats(self):\n",
    "        \"\"\"Return statistics about stored documents.\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            return \"No documents loaded.\"\n",
    "        count = self.vectorstore._collection.count()\n",
    "        logger.info(f\"Vectorstore stats: {count} documents\")\n",
    "        return f\"Number of documents: {count}\"\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the vectorstore.\"\"\"\n",
    "        try:\n",
    "            if self.db_dir.exists():\n",
    "                for item in self.db_dir.iterdir():\n",
    "                    if item.is_file():\n",
    "                        item.unlink()\n",
    "                    elif item.is_dir():\n",
    "                        for subitem in item.iterdir():\n",
    "                            subitem.unlink()\n",
    "                        item.rmdir()\n",
    "                self.db_dir.rmdir()\n",
    "            self.embed_documents()\n",
    "            logger.info(\"Vectorstore reset and re-embedded\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error resetting vectorstore: {e}\")\n",
    "\n",
    "# InsuranceMultiAgentSystem: Manages collaborative agents with enhanced Agno features\n",
    "class InsuranceMultiAgentSystem:\n",
    "    def __init__(self, rag_system, llm):\n",
    "        self.rag_system = rag_system\n",
    "        self.llm = llm\n",
    "        self.memory = ConversationBufferMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            return_messages=True\n",
    "        )\n",
    "        try:\n",
    "            self.sqlite_db = SqliteMemoryDb(table_name=\"insurance_memories\", db_file=\"tmp/agent.db\")\n",
    "            logger.info(\"Initialized SQLite memory at tmp/agent.db\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error initializing SQLite memory: {e}\")\n",
    "            raise\n",
    "        self.initialize_agents()\n",
    "\n",
    "    def initialize_agents(self):\n",
    "        \"\"\"Initialize the team of agents with Agno features.\"\"\"\n",
    "        # Define agent instructions\n",
    "        knowledge_retriever_instructions = [\n",
    "            \"You are a KnowledgeRetriever. Use the provided context to answer the user's question.\",\n",
    "            \"Focus on retrieving accurate information from insurance documents.\",\n",
    "            \"Use reasoning to ensure relevance and accuracy.\",\n",
    "            \"Summarize document content if it is lengthy.\"\n",
    "        ]\n",
    "        claims_specialist_instructions = [\n",
    "            \"You are a ClaimsSpecialist. Provide detailed guidance on handling insurance claims.\",\n",
    "            \"Explain steps clearly, including any documentation or processes required.\",\n",
    "            \"Use reasoning to address edge cases and potential user concerns.\"\n",
    "        ]\n",
    "        policy_advisor_instructions = [\n",
    "            \"You are a PolicyAdvisor. Offer expert advice on insurance policy options.\",\n",
    "            \"Explain policy types, coverage details, and considerations for choosing them.\",\n",
    "            \"Use reasoning to tailor advice to the user's query.\"\n",
    "        ]\n",
    "        customer_service_instructions = [\n",
    "            \"You are a CustomerService agent. Greet the user warmly and coordinate responses.\",\n",
    "            \"Ensure the user's question is clearly understood before passing it to other agents.\",\n",
    "            \"Use memory to personalize responses based on past interactions.\"\n",
    "        ]\n",
    "        lead_agent_instructions = [\n",
    "            \"You are a LeadAgent coordinating a team of specialized insurance agents.\",\n",
    "            \"Collect responses from the KnowledgeRetriever, ClaimsSpecialist, PolicyAdvisor, and CustomerService agents.\",\n",
    "            \"Use reasoning to summarize and refine their inputs into a clear, concise, and accurate response.\",\n",
    "            \"Return the response in JSON format with fields: 'answer' (string), 'sources' (list of strings), and 'confidence' (float between 0 and 1).\"\n",
    "        ]\n",
    "\n",
    "        # Initialize sub-agents with ReasoningTools and DocumentSummaryTool\n",
    "        self.knowledge_retriever = Agent(\n",
    "            name=\"KnowledgeRetriever\",\n",
    "            model=self.llm,\n",
    "            instructions=knowledge_retriever_instructions,\n",
    "            tools=[ReasoningTools(add_instructions=True), DocumentSummaryTool()],\n",
    "            memory=Memory(db=self.sqlite_db),\n",
    "            enable_agentic_memory=True,\n",
    "            description=\"Retrieves and summarizes information from insurance documents.\",\n",
    "            markdown=True\n",
    "        )\n",
    "        self.claims_specialist = Agent(\n",
    "            name=\"ClaimsSpecialist\",\n",
    "            model=self.llm,\n",
    "            instructions=claims_specialist_instructions,\n",
    "            tools=[ReasoningTools(add_instructions=True)],\n",
    "            memory=Memory(db=self.sqlite_db),\n",
    "            enable_agentic_memory=True,\n",
    "            description=\"Specializes in insurance claim processes.\",\n",
    "            markdown=True\n",
    "        )\n",
    "        self.policy_advisor = Agent(\n",
    "            name=\"PolicyAdvisor\",\n",
    "            model=self.llm,\n",
    "            instructions=policy_advisor_instructions,\n",
    "            tools=[ReasoningTools(add_instructions=True)],\n",
    "            memory=Memory(db=self.sqlite_db),\n",
    "            enable_agentic_memory=True,\n",
    "            description=\"Advises on insurance policy options.\",\n",
    "            markdown=True\n",
    "        )\n",
    "        self.customer_service = Agent(\n",
    "            name=\"CustomerService\",\n",
    "            model=self.llm,\n",
    "            instructions=customer_service_instructions,\n",
    "            tools=[ReasoningTools(add_instructions=True)],\n",
    "            memory=Memory(db=self.sqlite_db),\n",
    "            enable_agentic_memory=True,\n",
    "            description=\"Coordinates responses and greets users.\",\n",
    "            markdown=True\n",
    "        )\n",
    "\n",
    "        # Initialize lead agent with team\n",
    "        self.lead_agent = Agent(\n",
    "            name=\"LeadAgent\",\n",
    "            model=self.llm,\n",
    "            team=[self.knowledge_retriever, self.claims_specialist, self.policy_advisor, self.customer_service],\n",
    "            instructions=lead_agent_instructions,\n",
    "            tools=[ReasoningTools(add_instructions=True)],\n",
    "            memory=Memory(db=self.sqlite_db),\n",
    "            enable_agentic_memory=True,\n",
    "            description=\"Coordinates the insurance agent team and provides JSON responses.\",\n",
    "            markdown=True\n",
    "        )\n",
    "        logger.info(\"Agents initialized with ReasoningTools, DocumentSummaryTool, and SQLite memory\")\n",
    "\n",
    "    def _store_message(self, message: str, response: str):\n",
    "        \"\"\"Store a message and response in SQLite database.\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(\"tmp/agent.db\")\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS insurance_memories (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    message TEXT,\n",
    "                    response TEXT,\n",
    "                    timestamp TEXT\n",
    "                )\n",
    "            \"\"\")\n",
    "            cursor.execute(\n",
    "                \"INSERT INTO insurance_memories (message, response, timestamp) VALUES (?, ?, ?)\",\n",
    "                (message, response, datetime.now().isoformat())\n",
    "            )\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            logger.info(\"Stored message in SQLite database\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error storing message: {e}\")\n",
    "\n",
    "    def _retrieve_messages(self, limit: int = 3) -> List[Dict[str, str]]:\n",
    "        \"\"\"Retrieve recent messages from SQLite database.\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(\"tmp/agent.db\")\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\n",
    "                \"SELECT message, response FROM insurance_memories ORDER BY timestamp DESC LIMIT ?\",\n",
    "                (limit,)\n",
    "            )\n",
    "            messages = [{\"message\": row[0], \"response\": row[1]} for row in cursor.fetchall()]\n",
    "            conn.close()\n",
    "            logger.info(f\"Retrieved {len(messages)} messages from SQLite database\")\n",
    "            return messages\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error retrieving messages: {e}\")\n",
    "            return []\n",
    "\n",
    "    def answer_question(self, question):\n",
    "        \"\"\"Process a question through the agent team.\"\"\"\n",
    "        try:\n",
    "            # Retrieve recent memory messages\n",
    "            past_memories = self._retrieve_messages(limit=3)\n",
    "            memory_context = \"\\n\".join(\n",
    "                [f\"Past Q: {m['message']}\\nPast A: {m['response']}\" for m in past_memories]\n",
    "            )\n",
    "            if memory_context:\n",
    "                logger.info(\"Retrieved recent past memories for personalization\")\n",
    "            \n",
    "            # Retrieve relevant documents\n",
    "            docs = self.rag_system.search(question)\n",
    "            context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "            sources = [doc.metadata['source'] for doc in docs]\n",
    "            \n",
    "            # CustomerService initiates the conversation\n",
    "            cs_prompt = (\n",
    "                f\"Greetings! I'm here to help with your insurance question: {question}\\n\"\n",
    "                f\"Past interactions:\\n{memory_context}\\n\"\n",
    "                f\"Instructions: {self.customer_service.instructions[0]}\"\n",
    "            )\n",
    "            cs_response = self.llm.invoke(cs_prompt).content\n",
    "            \n",
    "            # KnowledgeRetriever uses document context and summarizes if needed\n",
    "            doc_summary = DocumentSummaryTool().run(context) if context else \"No relevant documents found.\"\n",
    "            kr_prompt = (\n",
    "                f\"Question: {question}\\n\"\n",
    "                f\"Document Summary: {doc_summary}\\n\"\n",
    "                f\"Raw Context: {context}\\n\"\n",
    "                f\"Instructions: {self.knowledge_retriever.instructions[0]}\"\n",
    "            )\n",
    "            kr_response = self.llm.invoke(kr_prompt).content\n",
    "            \n",
    "            # ClaimsSpecialist and PolicyAdvisor provide specialized input\n",
    "            cspecial_prompt = f\"Question: {question}\\nInstructions: {self.claims_specialist.instructions[0]}\"\n",
    "            cspecial_response = self.llm.invoke(cspecial_prompt).content\n",
    "            \n",
    "            pa_prompt = f\"Question: {question}\\nInstructions: {self.policy_advisor.instructions[0]}\"\n",
    "            pa_response = self.llm.invoke(pa_prompt).content\n",
    "            \n",
    "            # LeadAgent summarizes with JSON output\n",
    "            inputs = (\n",
    "                f\"CustomerService: {cs_response}\\n\"\n",
    "                f\"KnowledgeRetriever: {kr_response}\\n\"\n",
    "                f\"ClaimsSpecialist: {cspecial_response}\\n\"\n",
    "                f\"PolicyAdvisor: {pa_response}\"\n",
    "            )\n",
    "            json_response = self.llm.invoke(\n",
    "                f\"Question: {question}\\nInputs from team:\\n{inputs}\\nInstructions: {self.lead_agent.instructions[0]}\\n\"\n",
    "                \"Return the response in JSON format with fields: 'answer' (string), 'sources' (list of strings), and 'confidence' (float).\"\n",
    "            ).content\n",
    "            \n",
    "            try:\n",
    "                response_dict = json.loads(json_response)\n",
    "                if not isinstance(response_dict, dict) or 'answer' not in response_dict:\n",
    "                    response_dict = {\n",
    "                        'answer': json_response,\n",
    "                        'sources': sources,\n",
    "                        'confidence': 0.9\n",
    "                    }\n",
    "            except json.JSONDecodeError:\n",
    "                response_dict = {\n",
    "                    'answer': json_response,\n",
    "                    'sources': sources,\n",
    "                    'confidence': 0.9\n",
    "                }\n",
    "            \n",
    "            # Update LangChain and SQLite memory\n",
    "            self.memory.save_context({\"input\": question}, {\"output\": response_dict['answer']})\n",
    "            self._store_message(question, response_dict['answer'])\n",
    "            \n",
    "            logger.info(f\"Processed question: {question}\")\n",
    "            return response_dict, docs\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing question: {e}\")\n",
    "            return {\"answer\": \"An error occurred while processing your question.\", \"sources\": [], \"confidence\": 0.0}, []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a08df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main program\n",
    "def main():\n",
    "    # Initialize systems\n",
    "    rag_system = InsuranceRAGSystem()\n",
    "    multi_agent_system = InsuranceMultiAgentSystem(rag_system, llm)\n",
    "\n",
    "    # Test with sample questions\n",
    "    sample_questions = [\n",
    "        \"What types of auto insurance should I consider?\",\n",
    "        \"How do I file a home insurance claim?\"\n",
    "    ]\n",
    "\n",
    "    print(\"Testing with sample questions:\")\n",
    "    for question in sample_questions:\n",
    "        print(f\"\\nQuestion: {question}\")\n",
    "        response, docs = multi_agent_system.answer_question(question)\n",
    "        print(f\"Answer: {response['answer']}\")\n",
    "        print(f\"Sources: {response['sources']}\")\n",
    "        print(f\"Confidence: {response['confidence']}\")\n",
    "        print(\"Relevant Documents:\")\n",
    "        for doc in docs:\n",
    "            print(f\"- {doc.metadata['source']}: {doc.page_content[:100]}...\")\n",
    "\n",
    "    # Interactive mode\n",
    "    print(\"\\nInteractive Mode - Type your question or use commands: stats, search [query], reload, reset, quit\")\n",
    "    while True:\n",
    "        user_input = input(\"\\nYour input: \").strip()\n",
    "        if user_input.lower() == \"quit\":\n",
    "            break\n",
    "        elif user_input.lower() == \"stats\":\n",
    "            print(rag_system.stats())\n",
    "        elif user_input.lower().startswith(\"search \"):\n",
    "            query = user_input[7:].strip()\n",
    "            docs = rag_system.search(query)\n",
    "            print(\"Search Results:\")\n",
    "            for doc in docs:\n",
    "                print(f\"- {doc.metadata['source']}: {doc.page_content[:100]}...\")\n",
    "        elif user_input.lower() == \"reload\":\n",
    "            rag_system.embed_documents()\n",
    "            print(\"Documents reloaded.\")\n",
    "        elif user_input.lower() == \"reset\":\n",
    "            rag_system.reset()\n",
    "            print(\"Vectorstore reset.\")\n",
    "        else:\n",
    "            response, docs = multi_agent_system.answer_question(user_input)\n",
    "            print(f\"Answer: {response['answer']}\")\n",
    "            print(f\"Sources: {response['sources']}\")\n",
    "            print(f\"Confidence: {response['confidence']}\")\n",
    "            print(\"Relevant Documents:\")\n",
    "            for doc in docs:\n",
    "                print(f\"- {doc.metadata['source']}: {doc.page_content[:100]}...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
