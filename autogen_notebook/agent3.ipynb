{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f760e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict, Any\n",
    "from pathlib import Path\n",
    "\n",
    "# Core imports\n",
    "import autogen\n",
    "from autogen import ConversableAgent, GroupChat, GroupChatManager\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, Docx2txtLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import Document, HumanMessage\n",
    "\n",
    "# ChromaDB imports\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b9763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure Configuration\n",
    "AZURE_CONFIG = {\n",
    "    \"api_key\": ,\n",
    "    \"base_url\": \"\",\n",
    "    \"api_version\": \"2025-01-01-preview\",\n",
    "    \"embedding_deployment\": \"text-embedding-ada-002\",\n",
    "    \"gpt_deployment\": \"gpt-4o\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0feefb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InsuranceRAGSystem:\n",
    "    \"\"\"Enhanced Insurance RAG system with ChromaDB backend\"\"\"\n",
    "    \n",
    "    def __init__(self, data_folder: str = \"data\", persist_directory: str = \"chroma_db\"):\n",
    "        self.data_folder = data_folder\n",
    "        self.persist_directory = persist_directory\n",
    "        self.collection_name = \"insurance_documents\"\n",
    "        self.embeddings = None\n",
    "        self.vectorstore = None\n",
    "        self.llm = None\n",
    "        self.chroma_client = None\n",
    "        self.memory = ConversationBufferMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            return_messages=True\n",
    "        )\n",
    "        self.setup_azure_clients()\n",
    "        self.setup_chromadb()\n",
    "        # Ensure vectorstore is always initialized\n",
    "        self.create_or_load_vectorstore()\n",
    "        \n",
    "    def setup_azure_clients(self):\n",
    "        \"\"\"Initialize Azure OpenAI clients\"\"\"\n",
    "        try:\n",
    "            # Initialize embeddings\n",
    "            self.embeddings = AzureOpenAIEmbeddings(\n",
    "                azure_deployment=AZURE_CONFIG[\"embedding_deployment\"],\n",
    "                openai_api_version=AZURE_CONFIG[\"api_version\"],\n",
    "                azure_endpoint=AZURE_CONFIG[\"base_url\"],\n",
    "                openai_api_key=AZURE_CONFIG[\"api_key\"]\n",
    "            )\n",
    "            \n",
    "            # Initialize LLM\n",
    "            self.llm = AzureChatOpenAI(\n",
    "                azure_deployment=AZURE_CONFIG[\"gpt_deployment\"],\n",
    "                openai_api_version=AZURE_CONFIG[\"api_version\"],\n",
    "                azure_endpoint=AZURE_CONFIG[\"base_url\"],\n",
    "                openai_api_key=AZURE_CONFIG[\"api_key\"],\n",
    "                temperature=0.1,\n",
    "                max_retries=3,\n",
    "                request_timeout=60\n",
    "            )\n",
    "            print(\" Azure OpenAI clients initialized successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Error initializing Azure clients: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def setup_chromadb(self):\n",
    "        \"\"\"Initialize ChromaDB client for persistent storage\"\"\"\n",
    "        try:\n",
    "            # Ensure persist directory exists\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            \n",
    "            # Initialize ChromaDB client\n",
    "            self.chroma_client = chromadb.PersistentClient(\n",
    "                path=self.persist_directory,\n",
    "                settings=Settings(\n",
    "                    anonymized_telemetry=False,\n",
    "                    allow_reset=True\n",
    "                )\n",
    "            )\n",
    "            print(f\" ChromaDB client initialized at: {self.persist_directory}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Error initializing ChromaDB: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def load_and_process_documents(self) -> List[Document]:\n",
    "        \"\"\"Load and process insurance documents\"\"\"\n",
    "        try:\n",
    "            documents = []\n",
    "            \n",
    "            # Load PDF documents\n",
    "            pdf_files = list(Path(self.data_folder).glob(\"**/*.pdf\"))\n",
    "            for pdf_file in pdf_files:\n",
    "                try:\n",
    "                    loader = PyPDFLoader(str(pdf_file))\n",
    "                    docs = loader.load_and_split()\n",
    "                    documents.extend(docs)\n",
    "                    print(f\" Loaded PDF: {pdf_file.name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\" Error loading {pdf_file}: {e}\")\n",
    "            \n",
    "            # Load text documents\n",
    "            text_files = list(Path(self.data_folder).glob(\"**/*.txt\"))\n",
    "            for text_file in text_files:\n",
    "                try:\n",
    "                    loader = TextLoader(str(text_file), encoding='utf-8')\n",
    "                    docs = loader.load()\n",
    "                    documents.extend(docs)\n",
    "                    print(f\" Loaded text: {text_file.name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\" Error loading {text_file}: {e}\")\n",
    "            \n",
    "            # Load Word documents\n",
    "            docx_files = list(Path(self.data_folder).glob(\"**/*.docx\"))\n",
    "            for docx_file in docx_files:\n",
    "                try:\n",
    "                    loader = Docx2txtLoader(str(docx_file))\n",
    "                    docs = loader.load()\n",
    "                    documents.extend(docs)\n",
    "                    print(f\" Loaded DOCX: {docx_file.name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\" Error loading {docx_file}: {e}\")\n",
    "            \n",
    "            if not documents:\n",
    "                print(\" Creating sample insurance document\")\n",
    "                sample_doc = Document(\n",
    "                    page_content=\"\"\"\n",
    "                    Comprehensive Insurance Knowledge Base:\n",
    "                    \n",
    "                    AUTO INSURANCE:\n",
    "                    - Liability Coverage: Mandatory in most states, covers damages to others\n",
    "                    - Collision Coverage: Covers damage to your vehicle from accidents\n",
    "                    - Comprehensive Coverage: Non-collision damage (theft, weather, vandalism)\n",
    "                    - Personal Injury Protection (PIP): Medical expenses for you and passengers\n",
    "                    - Uninsured/Underinsured Motorist: Protection against drivers with insufficient coverage\n",
    "                    \n",
    "                    HOME INSURANCE:\n",
    "                    - Dwelling Coverage: Structure of your home\n",
    "                    - Personal Property: Belongings inside your home\n",
    "                    - Liability Protection: Accidents on your property\n",
    "                    - Additional Living Expenses (ALE): Temporary housing during repairs\n",
    "                    - Medical Payments: Minor medical expenses for guests\n",
    "                    \n",
    "                    LIFE INSURANCE:\n",
    "                    - Term Life: Fixed period coverage (10, 20, 30 years)\n",
    "                    - Whole Life: Permanent coverage with cash value\n",
    "                    - Universal Life: Flexible premiums and death benefits\n",
    "                    - Variable Life: Investment component with market exposure\n",
    "                    \n",
    "                    SPECIALTY COVERAGES:\n",
    "                    - Flood Insurance: Separate from standard home policies\n",
    "                    - Earthquake Coverage: Requires specific endorsement\n",
    "                    - Umbrella Policies: Extra liability protection\n",
    "                    - Professional Liability: For service providers\n",
    "                    \n",
    "                    CLAIMS PROCESS:\n",
    "                    1. Report incident immediately\n",
    "                    2. Document damage with photos/videos\n",
    "                    3. Submit required paperwork within 72 hours\n",
    "                    4. Adjuster assessment within 7 business days\n",
    "                    5. Settlement based on policy terms\n",
    "                    \n",
    "                    UNDERWRITING FACTORS:\n",
    "                    - Credit history\n",
    "                    - Claims history\n",
    "                    - Property location\n",
    "                    - Construction type\n",
    "                    - Coverage limits\n",
    "                    - Deductible selection\n",
    "                    \n",
    "                    SAMPLE POLICY FOR 25-YEAR-OLD:\n",
    "                    - Term Life Insurance: $500,000 coverage for 30 years\n",
    "                    - Premium: $35/month\n",
    "                    - Critical Illness Rider: Additional $20/month\n",
    "                    - Accidental Death Benefit: Included\n",
    "                    \"\"\",\n",
    "                    metadata={\"source\": \"sample_insurance_knowledge.txt\", \"type\": \"sample\"}\n",
    "                )\n",
    "                documents = [sample_doc]\n",
    "            \n",
    "            # Enhanced text splitting\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=1500,\n",
    "                chunk_overlap=300,\n",
    "                length_function=len,\n",
    "                separators=[\"\\n\\n‚Ä¢\", \"\\n‚Ä¢\", \"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "            )\n",
    "            \n",
    "            split_docs = text_splitter.split_documents(documents)\n",
    "            print(f\" Processed {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "            return split_docs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Error processing documents: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def create_or_load_vectorstore(self, documents: List[Document] = None, force_recreate: bool = False):\n",
    "        \"\"\"Create or load ChromaDB vectorstore\"\"\"\n",
    "        try:\n",
    "            existing_collections = [col.name for col in self.chroma_client.list_collections()]\n",
    "            collection_exists = self.collection_name in existing_collections\n",
    "            \n",
    "            if collection_exists and not force_recreate:\n",
    "                print(f\" Loading existing collection: {self.collection_name}\")\n",
    "                self.vectorstore = Chroma(\n",
    "                    client=self.chroma_client,\n",
    "                    collection_name=self.collection_name,\n",
    "                    embedding_function=self.embeddings\n",
    "                )\n",
    "                collection = self.chroma_client.get_collection(self.collection_name)\n",
    "                print(f\" Loaded {collection.count()} documents\")\n",
    "                \n",
    "            else:\n",
    "                if collection_exists:\n",
    "                    print(f\"Recreating collection: {self.collection_name}\")\n",
    "                    self.chroma_client.delete_collection(self.collection_name)\n",
    "                \n",
    "                if not documents:\n",
    "                    documents = self.load_and_process_documents()\n",
    "                \n",
    "                if not documents:\n",
    "                    print(\" No documents available, creating sample knowledge base\")\n",
    "                    documents = self.load_and_process_documents()  # Retry creating sample\n",
    "                \n",
    "                print(f\" Creating new collection: {self.collection_name}\")\n",
    "                self.vectorstore = Chroma.from_documents(\n",
    "                    documents=documents,\n",
    "                    embedding=self.embeddings,\n",
    "                    client=self.chroma_client,\n",
    "                    collection_name=self.collection_name,\n",
    "                    persist_directory=self.persist_directory\n",
    "                )\n",
    "                self.vectorstore.persist()\n",
    "                print(f\" Created vectorstore with {len(documents)} chunks\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Vectorstore error: {e}\")\n",
    "            # Create sample documents as fallback\n",
    "            print(\" Creating fallback sample knowledge base\")\n",
    "            sample_doc = Document(\n",
    "                page_content=\"Fallback insurance knowledge base\",\n",
    "                metadata={\"source\": \"fallback.txt\", \"type\": \"sample\"}\n",
    "            )\n",
    "            self.vectorstore = Chroma.from_documents(\n",
    "                documents=[sample_doc],\n",
    "                embedding=self.embeddings,\n",
    "                client=self.chroma_client,\n",
    "                collection_name=self.collection_name,\n",
    "                persist_directory=self.persist_directory\n",
    "            )\n",
    "    \n",
    "    def retrieve_context(self, query: str, k: int = 5) -> str:\n",
    "        \"\"\"Retrieve relevant context with metadata\"\"\"\n",
    "        try:\n",
    "            if not self.vectorstore:\n",
    "                self.create_or_load_vectorstore()  # Ensure vectorstore exists\n",
    "                if not self.vectorstore:\n",
    "                    return \"Knowledge base not available\"\n",
    "            \n",
    "            results = self.vectorstore.similarity_search_with_score(query, k=k)\n",
    "            \n",
    "            context_parts = []\n",
    "            for i, (doc, score) in enumerate(results, 1):\n",
    "                metadata = doc.metadata\n",
    "                source = metadata.get(\"source\", \"Unknown document\")\n",
    "                page = metadata.get(\"page\", \"N/A\")\n",
    "                relevance = 1 - score\n",
    "                \n",
    "                context_parts.append(\n",
    "                    f\" Source {i}: {source} (Page {page}, Relevance: {relevance:.2f})\\n\"\n",
    "                    f\"{doc.page_content[:500]}{'...' if len(doc.page_content) > 500 else ''}\"\n",
    "                )\n",
    "            \n",
    "            return \"\\n\\n\".join(context_parts)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Retrieval error: {e}\")\n",
    "            return \"Error retrieving information\"\n",
    "    \n",
    "    def search_documents(self, query: str, k: int = 5) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search documents with detailed metadata\"\"\"\n",
    "        try:\n",
    "            if not self.vectorstore:\n",
    "                return []\n",
    "            \n",
    "            results = self.vectorstore.similarity_search_with_score(query, k=k)\n",
    "            \n",
    "            search_results = []\n",
    "            for doc, score in results:\n",
    "                metadata = doc.metadata\n",
    "                search_results.append({\n",
    "                    \"content\": doc.page_content,\n",
    "                    \"metadata\": metadata,\n",
    "                    \"relevance_score\": 1 - score,\n",
    "                    \"source\": metadata.get(\"source\", \"Unknown\"),\n",
    "                    \"page\": metadata.get(\"page\", \"N/A\")\n",
    "                })\n",
    "            \n",
    "            return search_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Search error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_collection_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get ChromaDB statistics\"\"\"\n",
    "        try:\n",
    "            stats = {\n",
    "                \"persist_directory\": self.persist_directory,\n",
    "                \"collection\": self.collection_name,\n",
    "                \"embedding_model\": AZURE_CONFIG[\"embedding_deployment\"]\n",
    "            }\n",
    "            \n",
    "            if self.chroma_client:\n",
    "                collections = self.chroma_client.list_collections()\n",
    "                stats[\"collections\"] = [col.name for col in collections]\n",
    "                \n",
    "                if self.collection_name in stats[\"collections\"]:\n",
    "                    collection = self.chroma_client.get_collection(self.collection_name)\n",
    "                    stats[\"document_count\"] = collection.count()\n",
    "            \n",
    "            return stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "    \n",
    "    def reset_vectorstore(self):\n",
    "        \"\"\"Reset ChromaDB collection\"\"\"\n",
    "        try:\n",
    "            if self.chroma_client and self.collection_name in [col.name for col in self.chroma_client.list_collections()]:\n",
    "                self.chroma_client.delete_collection(self.collection_name)\n",
    "                print(f\"Deleted collection: {self.collection_name}\")\n",
    "            \n",
    "            self.vectorstore = None\n",
    "            print(\" Vectorstore reset\")\n",
    "            # Reinitialize after reset\n",
    "            self.create_or_load_vectorstore()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Reset error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bb3f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class InsuranceMultiAgentSystem:\n",
    "    \"\"\"Enhanced multi-agent system for insurance processing with detailed agent tracking\"\"\"\n",
    "    \n",
    "    def __init__(self, rag_system: InsuranceRAGSystem):\n",
    "        self.rag_system = rag_system\n",
    "        self.agents = {}\n",
    "        self.group_chat = None\n",
    "        self.manager = None\n",
    "        self.setup_agents()\n",
    "        self.setup_group_chat()\n",
    "    \n",
    "    def setup_agents(self):\n",
    "        \"\"\"Initialize specialized insurance agents with enhanced functionality\"\"\"\n",
    "        config_list = [{\n",
    "            \"model\": AZURE_CONFIG[\"gpt_deployment\"],\n",
    "            \"api_type\": \"azure\",\n",
    "            \"base_url\": AZURE_CONFIG[\"base_url\"],\n",
    "            \"api_key\": AZURE_CONFIG[\"api_key\"],\n",
    "            \"api_version\": AZURE_CONFIG[\"api_version\"]\n",
    "        }]\n",
    "        \n",
    "        llm_config = {\n",
    "            \"config_list\": config_list,\n",
    "            \"temperature\": 0.1,\n",
    "            \"timeout\": 120,\n",
    "            \"cache_seed\": 42\n",
    "        }\n",
    "        \n",
    "        # Knowledge Retrieval Agent\n",
    "        self.agents[\"retriever\"] = ConversableAgent(\n",
    "            name=\"KnowledgeRetriever\",\n",
    "            system_message=\"\"\"You are an Insurance Knowledge Specialist. Your responsibilities:\n",
    "            - Retrieve accurate policy information from ChromaDB knowledge base\n",
    "            - Provide citations with source documents\n",
    "            - Filter irrelevant information\n",
    "            - Identify knowledge gaps in the database\n",
    "            - Never guess or speculate beyond available information\"\"\",\n",
    "            llm_config=llm_config,\n",
    "            human_input_mode=\"NEVER\",\n",
    "            max_consecutive_auto_reply=2\n",
    "        )\n",
    "        \n",
    "        # Claims Processing Agent\n",
    "        self.agents[\"claims_agent\"] = ConversableAgent(\n",
    "            name=\"ClaimsSpecialist\",\n",
    "            system_message=\"\"\"You are a Senior Claims Adjuster with 10+ years experience. Responsibilities:\n",
    "            - Guide customers through claims process\n",
    "            - Explain documentation requirements\n",
    "            - Calculate settlement estimates\n",
    "            - Identify coverage limitations\n",
    "            - Handle complex claims (multi-vehicle, natural disasters)\n",
    "            - Provide empathetic support during stressful situations\"\"\",\n",
    "            llm_config=llm_config,\n",
    "            human_input_mode=\"NEVER\",\n",
    "            max_consecutive_auto_reply=3\n",
    "        )\n",
    "        \n",
    "        # Policy Advisor Agent\n",
    "        self.agents[\"policy_advisor\"] = ConversableAgent(\n",
    "            name=\"PolicyAdvisor\",\n",
    "            system_message=\"\"\"You are a Licensed Policy Consultant. Responsibilities:\n",
    "            - Explain coverage options and limitations\n",
    "            - Recommend policy enhancements based on life changes\n",
    "            - Compare insurance products across providers\n",
    "            - Analyze premium/deductible tradeoffs\n",
    "            - Identify coverage gaps\n",
    "            - Explain riders and endorsements\"\"\",\n",
    "            llm_config=llm_config,\n",
    "            human_input_mode=\"NEVER\",\n",
    "            max_consecutive_auto_reply=3\n",
    "        )\n",
    "        \n",
    "        # Customer Service Agent\n",
    "        self.agents[\"customer_service\"] = ConversableAgent(\n",
    "            name=\"CustomerService\",\n",
    "            system_message=\"\"\"You are the Primary Customer Interface. Responsibilities:\n",
    "            - Triage inquiries to appropriate specialists\n",
    "            - Maintain conversation context and history\n",
    "            - Provide policy documentation\n",
    "            - Handle billing inquiries\n",
    "            - Ensure customer satisfaction\n",
    "            - Escalate complex issues\"\"\",\n",
    "            llm_config=llm_config,\n",
    "            human_input_mode=\"NEVER\",\n",
    "            max_consecutive_auto_reply=2\n",
    "        )\n",
    "        \n",
    "        # Compliance Agent\n",
    "        self.agents[\"compliance_agent\"] = ConversableAgent(\n",
    "            name=\"ComplianceOfficer\",\n",
    "            system_message=\"\"\"You are an Insurance Compliance Specialist. Responsibilities:\n",
    "            - Ensure regulatory compliance (NAIC, state-specific)\n",
    "            - Verify accurate coverage descriptions\n",
    "            - Review policy limitations and exclusions\n",
    "            - Monitor for unfair claims practices\n",
    "            - Ensure proper disclosures\n",
    "            - Maintain documentation standards\"\"\",\n",
    "            llm_config=llm_config,\n",
    "            human_input_mode=\"NEVER\",\n",
    "            max_consecutive_auto_reply=2\n",
    "        )\n",
    "        \n",
    "        # Underwriting Agent\n",
    "        self.agents[\"underwriting_agent\"] = ConversableAgent(\n",
    "            name=\"UnderwritingSpecialist\",\n",
    "            system_message=\"\"\"You are a Senior Underwriter. Responsibilities:\n",
    "            - Assess risk profiles for policy applications\n",
    "            - Determine appropriate coverage levels\n",
    "            - Calculate premiums based on risk assessment\n",
    "            - Identify special underwriting considerations\n",
    "            - Recommend policy terms and conditions\"\"\",\n",
    "            llm_config=llm_config,\n",
    "            human_input_mode=\"NEVER\",\n",
    "            max_consecutive_auto_reply=3\n",
    "        )\n",
    "        \n",
    "        # Fraud Detection Agent\n",
    "        self.agents[\"fraud_detector\"] = ConversableAgent(\n",
    "            name=\"FraudDetection\",\n",
    "            system_message=\"\"\"You are a Fraud Detection Analyst. Responsibilities:\n",
    "            - Identify suspicious claim patterns\n",
    "            - Detect inconsistencies in documentation\n",
    "            - Recommend investigation strategies\n",
    "            - Maintain fraud detection protocols\n",
    "            - Ensure compliance with anti-fraud regulations\"\"\",\n",
    "            llm_config=llm_config,\n",
    "            human_input_mode=\"NEVER\",\n",
    "            max_consecutive_auto_reply=2\n",
    "        )\n",
    "        \n",
    "        # Supervisor Agent - FIXED TERMINATION ISSUE\n",
    "        self.agents[\"supervisor\"] = ConversableAgent(\n",
    "            name=\"Supervisor\",\n",
    "            system_message=\"\"\"You are the Team Supervisor. Responsibilities:\n",
    "            - Coordinate agent responses\n",
    "            - Ensure comprehensive coverage of all issues\n",
    "            - Resolve inter-agent disagreements\n",
    "            - Finalize responses after compliance review\n",
    "            - Maintain service quality standards\n",
    "            - In your final response, state which agent primarily handled the query\n",
    "            - Include source references when available\n",
    "            - DO NOT include the word TERMINATE in your response\"\"\",  # Removed termination trigger\n",
    "            llm_config=llm_config,\n",
    "            human_input_mode=\"NEVER\",\n",
    "            max_consecutive_auto_reply=1,\n",
    "            # Removed termination condition to prevent premature ending\n",
    "        )\n",
    "    \n",
    "    def setup_group_chat(self):\n",
    "        \"\"\"Configure group chat workflow\"\"\"\n",
    "        agent_list = [\n",
    "            self.agents[\"customer_service\"],\n",
    "            self.agents[\"retriever\"],\n",
    "            self.agents[\"claims_agent\"],\n",
    "            self.agents[\"policy_advisor\"],\n",
    "            self.agents[\"underwriting_agent\"],\n",
    "            self.agents[\"fraud_detector\"],\n",
    "            self.agents[\"compliance_agent\"],\n",
    "            self.agents[\"supervisor\"]\n",
    "        ]\n",
    "        \n",
    "        self.group_chat = GroupChat(\n",
    "            agents=agent_list,\n",
    "            messages=[],\n",
    "            max_round=12,\n",
    "            speaker_selection_method=\"auto\",\n",
    "            allow_repeat_speaker=False\n",
    "        )\n",
    "        \n",
    "        manager_config = [{\n",
    "            \"model\": AZURE_CONFIG[\"gpt_deployment\"],\n",
    "            \"api_type\": \"azure\",\n",
    "            \"base_url\": AZURE_CONFIG[\"base_url\"],\n",
    "            \"api_key\": AZURE_CONFIG[\"api_key\"],\n",
    "            \"api_version\": AZURE_CONFIG[\"api_version\"]\n",
    "        }]\n",
    "        \n",
    "        self.manager = GroupChatManager(\n",
    "            groupchat=self.group_chat,\n",
    "            llm_config={\"config_list\": manager_config, \"temperature\": 0.1}\n",
    "        )\n",
    "    \n",
    "    def process_query(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Process insurance query through multi-agent system with detailed agent tracking\"\"\"\n",
    "        try:\n",
    "            # Retrieve context before agent processing\n",
    "            context = self.rag_system.retrieve_context(query)\n",
    "            search_results = self.rag_system.search_documents(query, k=3)\n",
    "            \n",
    "            enhanced_query = f\"\"\"\n",
    "            ## INSURANCE QUERY PROCESSING ##\n",
    "            Customer Query: {query}\n",
    "            \n",
    "            Relevant Context from Knowledge Base:\n",
    "            {context if context else 'No relevant context found'}\n",
    "            \n",
    "            Processing Instructions:\n",
    "            1. KnowledgeRetriever: Verify policy details\n",
    "            2. Specialist Agents: Address specific aspects\n",
    "            3. ComplianceOfficer: Validate regulatory compliance\n",
    "            4. Supervisor: Finalize response and state primary agent\n",
    "            5. Include source references in final response\n",
    "            \"\"\"\n",
    "            \n",
    "            self.rag_system.memory.chat_memory.add_user_message(query)\n",
    "            chat_result = self.agents[\"customer_service\"].initiate_chat(\n",
    "                self.manager,\n",
    "                message=enhanced_query,\n",
    "                clear_history=True,\n",
    "                silent=True  # Set to False for debugging\n",
    "            )\n",
    "            \n",
    "            # Extract final response and agent information\n",
    "            final_response = \"\"\n",
    "            primary_agent = \"Unknown\"\n",
    "            all_agents = set()\n",
    "            \n",
    "            if chat_result.chat_history:\n",
    "                # Get all unique agents involved\n",
    "                all_agents = {msg[\"name\"] for msg in chat_result.chat_history}\n",
    "                \n",
    "                # Extract the final response from supervisor\n",
    "                for msg in reversed(chat_result.chat_history):\n",
    "                    if msg[\"name\"] == \"Supervisor\" and \"content\" in msg:\n",
    "                        final_response = msg[\"content\"]\n",
    "                        break\n",
    "                \n",
    "                # Determine primary agent - first specialist to respond\n",
    "                specialist_agents = [\"ClaimsSpecialist\", \"PolicyAdvisor\", \n",
    "                                    \"UnderwritingSpecialist\", \"FraudDetection\"]\n",
    "                for msg in chat_result.chat_history:\n",
    "                    if msg[\"name\"] in specialist_agents:\n",
    "                        primary_agent = msg[\"name\"]\n",
    "                        break\n",
    "            \n",
    "            # If supervisor didn't identify primary, try to parse from response\n",
    "            if \"primarily handled by\" not in final_response.lower():\n",
    "                # Try to determine primary agent from response content\n",
    "                for agent_name in specialist_agents:\n",
    "                    if agent_name.lower() in final_response.lower():\n",
    "                        primary_agent = agent_name\n",
    "                        break\n",
    "                \n",
    "                # Add primary agent declaration to response\n",
    "                final_response = f\"This query was primarily handled by {primary_agent}.\\n\\n{final_response}\"\n",
    "            \n",
    "            self.rag_system.memory.chat_memory.add_ai_message(final_response)\n",
    "            \n",
    "            # Format agent list for display\n",
    "            agent_list = list(all_agents)\n",
    "            agent_list.sort()\n",
    "            agents_involved = \", \".join(agent_list)\n",
    "            \n",
    "            return {\n",
    "                \"query\": query,\n",
    "                \"response\": final_response,\n",
    "                \"primary_agent\": primary_agent,\n",
    "                \"agents_involved\": agents_involved,\n",
    "                \"knowledge_used\": bool(context.strip()),\n",
    "                \"search_results\": search_results\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Processing error: {e}\")\n",
    "            return {\n",
    "                \"query\": query,\n",
    "                \"response\": f\"System error: {str(e)}\",\n",
    "                \"primary_agent\": \"Error\",\n",
    "                \"agents_involved\": \"\",\n",
    "                \"knowledge_used\": False,\n",
    "                \"search_results\": []\n",
    "            }\n",
    "    \n",
    "    def simple_query(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Direct RAG response for simple queries with agent simulation\"\"\"\n",
    "        try:\n",
    "            context = self.rag_system.retrieve_context(query)\n",
    "            search_results = self.rag_system.search_documents(query, k=3)\n",
    "            \n",
    "            prompt = f\"\"\"\n",
    "            [Insurance Expert Mode]\n",
    "            Answer the customer's question using ONLY the provided context.\n",
    "            Include source references when available.\n",
    "            \n",
    "            Question: {query}\n",
    "            \n",
    "            Context:\n",
    "            {context if context else 'No relevant information available'}\n",
    "            \n",
    "            Instructions:\n",
    "            1. Answer concisely (1-2 paragraphs)\n",
    "            2. Cite sources when available\n",
    "            3. If context is insufficient, state: \"Based on my knowledge: [answer]. Consult your policy for specifics.\"\n",
    "            4. Never speculate beyond provided information\n",
    "            \"\"\"\n",
    "            \n",
    "            response = self.rag_system.llm.invoke([HumanMessage(content=prompt)])\n",
    "            \n",
    "            # Simulate agent involvement for simple queries\n",
    "            return {\n",
    "                \"query\": query,\n",
    "                \"response\": response.content,\n",
    "                \"primary_agent\": \"KnowledgeRetriever\",\n",
    "                \"agents_involved\": \"KnowledgeRetriever, CustomerService\",\n",
    "                \"knowledge_used\": bool(context.strip()),\n",
    "                \"search_results\": search_results\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Simple query error: {e}\")\n",
    "            return {\n",
    "                \"query\": query,\n",
    "                \"response\": f\"System error: {str(e)}\",\n",
    "                \"primary_agent\": \"Error\",\n",
    "                \"agents_involved\": \"\",\n",
    "                \"knowledge_used\": False,\n",
    "                \"search_results\": []\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2adb639",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    \"\"\"Main application flow with enhanced agent reporting\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"INSURANCE MULTI-AGENT RAG SYSTEM WITH CHROMADB\".center(70))\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    try:\n",
    "        # Initialize RAG system\n",
    "        print(\"\\nüîß Initializing RAG system...\")\n",
    "        rag_system = InsuranceRAGSystem(\n",
    "            data_folder=\"data\",\n",
    "            persist_directory=\"chroma_db\"\n",
    "        )\n",
    "        \n",
    "        # Check existing vectorstore\n",
    "        stats = rag_system.get_collection_stats()\n",
    "        doc_count = stats.get(\"document_count\", 0)\n",
    "        print(f\" ChromaDB Status: {doc_count} documents in '{stats.get('collection', '')}'\")\n",
    "        \n",
    "        if doc_count < 10:\n",
    "            print(\"\\n Loading documents...\")\n",
    "            rag_system.create_or_load_vectorstore()\n",
    "            stats = rag_system.get_collection_stats()\n",
    "            print(f\"New Status: {stats.get('document_count', 0)} documents\")\n",
    "        \n",
    "        # Initialize agent system\n",
    "        print(\"\\n Initializing multi-agent system...\")\n",
    "        agent_system = InsuranceMultiAgentSystem(rag_system)\n",
    "        print(\" System ready with 8 specialized agents\")\n",
    "        \n",
    "        # Interactive mode\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\" INTERACTIVE MODE - Ask insurance questions\".center(70))\n",
    "        print(\" Commands: stats, search [query], reload, reset, quit\".center(70))\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                user_input = input(\"\\n Your question: \").strip()\n",
    "                \n",
    "                if not user_input:\n",
    "                    continue\n",
    "                    \n",
    "                if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "                    print(\"\\n Thank you for using the Insurance Assistant!\")\n",
    "                    break\n",
    "                    \n",
    "                # Handle special commands\n",
    "                if user_input.lower() == 'stats':\n",
    "                    stats = rag_system.get_collection_stats()\n",
    "                    print(\"\\n ChromaDB Statistics:\")\n",
    "                    for key, value in stats.items():\n",
    "                        print(f\"  - {key}: {value}\")\n",
    "                    continue\n",
    "                    \n",
    "                if user_input.lower().startswith('search '):\n",
    "                    query = user_input[7:].strip()\n",
    "                    print(f\"\\n Searching for: '{query}'\")\n",
    "                    results = rag_system.search_documents(query, k=3)\n",
    "                    \n",
    "                    if results:\n",
    "                        for i, result in enumerate(results, 1):\n",
    "                            print(f\"\\n Result {i}:\")\n",
    "                            print(f\"   Source: {result.get('source', 'Unknown')}\")\n",
    "                            print(f\"   Page: {result.get('page', 'N/A')}\")\n",
    "                            print(f\"   Relevance: {result.get('relevance_score', 0):.3f}\")\n",
    "                            print(f\"   Content: {result['content'][:150]}...\")\n",
    "                    else:\n",
    "                        print(\" No results found\")\n",
    "                    continue\n",
    "                    \n",
    "                if user_input.lower() == 'reload':\n",
    "                    print(\"\\n Reloading documents...\")\n",
    "                    rag_system.create_or_load_vectorstore(force_recreate=True)\n",
    "                    print(\" Documents reloaded successfully!\")\n",
    "                    continue\n",
    "                    \n",
    "                if user_input.lower() == 'reset':\n",
    "                    confirm = input(\" Delete ALL documents? (yes/no): \")\n",
    "                    if confirm.lower() in ['yes', 'y']:\n",
    "                        rag_system.reset_vectorstore()\n",
    "                        print(\" ChromaDB reset complete\")\n",
    "                    continue\n",
    "                \n",
    "                # Process query\n",
    "                start_time = time.time()\n",
    "                print(\"\\n Processing your query with our agent team...\")\n",
    "                \n",
    "                # Use multi-agent for complex queries, simple for others\n",
    "                if \"claim\" in user_input.lower() or \"policy\" in user_input.lower() or \"coverage\" in user_input.lower():\n",
    "                    result = agent_system.process_query(user_input)\n",
    "                else:\n",
    "                    result = agent_system.simple_query(user_input)\n",
    "                \n",
    "                # Display results with agent information\n",
    "                print(\"\\n\" + \"-\" * 70)\n",
    "                print(f\" Query: {user_input}\")\n",
    "                print(f\" Primarily handled by: {result['primary_agent']}\")\n",
    "                print(f\" Agents involved: {result['agents_involved']}\")\n",
    "                print(f\" Knowledge base was consulted: {'Yes' if result['knowledge_used'] else 'No'}\")\n",
    "                print(\"-\" * 70)\n",
    "                \n",
    "                # Display response\n",
    "                print(\"\\n Response:\")\n",
    "                print(\"-\" * 70)\n",
    "                print(result[\"response\"])\n",
    "                print(\"-\" * 70)\n",
    "                print(f\"‚è±  Response time: {time.time() - start_time:.2f} seconds\")\n",
    "                \n",
    "                # Show relevant sources if available\n",
    "                if result.get(\"search_results\"):\n",
    "                    print(\"\\n Relevant Sources:\")\n",
    "                    for i, res in enumerate(result[\"search_results\"][:3], 1):\n",
    "                        source = res.get('source', 'Unknown')\n",
    "                        page = res.get('page', 'N/A')\n",
    "                        relevance = res.get('relevance_score', 0)\n",
    "                        print(f\"  {i}. {source} (Page {page}, Relevance: {relevance:.2f})\")\n",
    "                elif result[\"knowledge_used\"]:\n",
    "                    print(\"\\n Knowledge base was consulted but no specific sources are available\")\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n Operation cancelled\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\n Error: {str(e)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n Fatal error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "243d09a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "            INSURANCE MULTI-AGENT RAG SYSTEM WITH CHROMADB            \n",
      "======================================================================\n",
      "\n",
      "üîß Initializing RAG system...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhanu\\AppData\\Local\\Temp\\ipykernel_23336\\3574312706.py:12: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  self.memory = ConversationBufferMemory(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Azure OpenAI clients initialized successfully\n",
      "üîµ ChromaDB client initialized at: chroma_db\n",
      "‚ôªÔ∏è Loading existing collection: insurance_documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhanu\\AppData\\Local\\Temp\\ipykernel_23336\\3574312706.py:187: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  self.vectorstore = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Loaded 316 documents\n",
      "üìä ChromaDB Status: 316 documents in 'insurance_documents'\n",
      "\n",
      "ü§ñ Initializing multi-agent system...\n",
      "‚úÖ System ready with 8 specialized agents\n",
      "\n",
      "======================================================================\n",
      "             üí¨ INTERACTIVE MODE - Ask insurance questions             \n",
      "        üîß Commands: stats, search [query], reload, reset, quit        \n",
      "======================================================================\n",
      "\n",
      "‚è≥ Processing your query with our agent team...\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "üßë‚Äçüíº Query: suggest me some HLA policies\n",
      "ü§ñ Primarily handled by: KnowledgeRetriever\n",
      "ü§ñ Agents involved: KnowledgeRetriever, CustomerService\n",
      "üìö Knowledge base was consulted: Yes\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üí° Response:\n",
      "----------------------------------------------------------------------\n",
      "Based on the provided context, here are two HLA policies you may consider:\n",
      "\n",
      "1. **HLA CompleteProtect**: This policy offers enhanced protection to help you embrace life's uncertainties. It is underwritten by Hong Leong Assurance Berhad and regulated by Bank Negara Malaysia. The policy emphasizes affordability and flexibility, allowing you to select riders that best suit your needs. For more details, you can contact HLA at 03-7650 1288 or visit their website at www.hla.com.my. (Source: HLA CompleteProtect Brochure, Pages 0 and 12)\n",
      "\n",
      "2. **HLA Life Essential**: This plan provides two choices of coverage tailored for individuals and businesses. It focuses on building a strong foundation of protection for you and your family, ensuring basic needs are covered while remaining affordable and flexible for enhancements. For specific terms and conditions, refer to the Product Disclosure Sheet and Sales Illustration. (Source: HLA Life Essential Product Brochure, Pages 0 and 1)\n",
      "\n",
      "For further information, consult your HLA agent or review the respective product brochures.\n",
      "----------------------------------------------------------------------\n",
      "‚è±Ô∏è  Response time: 4.61 seconds\n",
      "\n",
      "üìö Relevant Sources:\n",
      "  1. data\\Data\\HLA CompleteProtect Brochure (EN)_v3.pdf (Page 12, Relevance: 0.63)\n",
      "  2. data\\Data\\HLA Life Essential Product Brochure.pdf (Page 0, Relevance: 0.62)\n",
      "  3. data\\Data\\HLA Life Essential Product Brochure.pdf (Page 1, Relevance: 0.62)\n",
      "\n",
      "üëã Thank you for using the Insurance Assistant!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1fcceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f7a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e92ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c8a146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
